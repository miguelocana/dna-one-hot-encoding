seq_onehot <- append(seq_onehot, c(1,0,0,0))
} else {
print("ERROR: al menos un carácter de la secuencia introducida no corresponde a ningún nucleótido (A,G,C,T).")
break
}
}
for (k in 1:length(seq_onehot)) {
ind <- grep(paste(onehot_cols_name,k,sep=""), colnames(df2))
df2[j,ind] <- seq_onehot[k]
}
}
# Elimina o no la columna con la secuencia
if (remove_col_seq) {
df3 <- df2[,c(x[-grep(col_seq, colnames(df2))])]
} else {
df3 <- df2
}
}
promoters <- read.csv('promoters.txt',header = FALSE,sep=',')
promoters <- read.csv('promoters.txt',header = FALSE,sep=',')
prueba <- onehot(df=promoters, col_seq = 'V3', onehot_cols_name = 'P-', remove_col_seq = TRUE)
onehot <- function (df, col_seq, onehot_cols_name='H', remove_col_seq = FALSE) {
# Se asegura de que todas las seq tengan el mismo tamaño (de lo contrario salta ERROR)
f <- length(strsplit(df[col_seq][[1]], "")[[1]])
for (j in 1:nrow(df)) {
a = length(strsplit(df[j,col_seq], "")[[1]])
if (a == f) {
next
} else {
print('ERROR: al menos una secuencia no tiene el mismo tamaño que el resto.')
break
}
}
# Crea una columna por cada dígito del one-hot
num_cols <- f * 4
cols_onehot <- list()
for (i in 1:num_cols) {
cols_onehot <- append(cols_onehot,paste(onehot_cols_name,i,sep=""))
}
# Añade las columnas (vacías) al nuevo DF
df2 <- df
for (i in cols_onehot) {
df2[,i] <- NA
}
# Traducción de seq a one-hot encoding
for (j in 1:nrow(df2)) {
seq = strsplit(tolower(df2[j,col_seq]), "")[[1]] # convierte la seq en minuscula
seq_onehot <- list()
for (i in seq) {
if (i == 'a') {
seq_onehot <- append(seq_onehot, c(0,0,0,1))
} else if (i == 'g') {
seq_onehot <- append(seq_onehot, c(0,0,1,0))
} else if (i == 'c') {
seq_onehot <- append(seq_onehot, c(0,1,0,0))
} else if (i == 't') {
seq_onehot <- append(seq_onehot, c(1,0,0,0))
} else {
print("ERROR: al menos un carácter de la secuencia introducida no corresponde a ningún nucleótido (A,G,C,T).")
break
}
}
for (k in 1:length(seq_onehot)) {
ind <- grep(paste(onehot_cols_name,k,sep=""), colnames(df2))
df2[j,ind] <- seq_onehot[k]
}
}
# Elimina o no la columna con la secuencia
if (remove_col_seq) {
df3 <- df2[,c(colnames(df2)[-grep(col_seq, colnames(df2))])]
} else {
df3 <- df2
}
# Devuelve el df con one-hot encoding
return (df3)
}
prueba <- onehot(df=promoters, col_seq = 'V3', onehot_cols_name = 'P-', remove_col_seq = TRUE)
View(prueba)
prueba <- onehot(df=promoters, col_seq = 'V2', onehot_cols_name = 'P-', remove_col_seq = TRUE)
onehot <- function (df, col_seq, onehot_cols_name='H', remove_col_seq = FALSE) {
# Se asegura de que todas las seq tengan el mismo tamaño (de lo contrario salta ERROR)
f <- length(strsplit(df[col_seq][[1]], "")[[1]])
for (j in 1:nrow(df)) {
a = length(strsplit(df[j,col_seq], "")[[1]])
if (a == f) {
next
} else {
print('ERROR: al menos una secuencia no tiene el mismo tamaño que el resto.')
break
}
}
# Crea una columna por cada dígito del one-hot
num_cols <- f * 4
cols_onehot <- list()
for (i in 1:num_cols) {
cols_onehot <- append(cols_onehot,paste(onehot_cols_name,i,sep=""))
}
# Añade las columnas (vacías) al nuevo DF
df2 <- df
for (i in cols_onehot) {
df2[,i] <- NA
}
# Traducción de seq a one-hot encoding
for (j in 1:nrow(df2)) {
seq = strsplit(tolower(df2[j,col_seq]), "")[[1]] # convierte la seq en minuscula
seq_onehot <- list()
for (i in seq) {
if (i == 'a') {
seq_onehot <- append(seq_onehot, c(0,0,0,1))
} else if (i == 'g') {
seq_onehot <- append(seq_onehot, c(0,0,1,0))
} else if (i == 'c') {
seq_onehot <- append(seq_onehot, c(0,1,0,0))
} else if (i == 't') {
seq_onehot <- append(seq_onehot, c(1,0,0,0))
} else {
print("ERROR: al menos un carácter de la secuencia introducida no corresponde a ningún nucleótido (A,G,C,T).")
break
}
}
for (k in 1:length(seq_onehot)) {
ind <- grep(paste(onehot_cols_name,k,sep=""), colnames(df2))
df2[j,ind] <- seq_onehot[k]
}
}
# Elimina o no la columna con la secuencia
if (remove_col_seq) {
df3 <- df2[,c(colnames(df2)[-grep(col_seq, colnames(df2))])]
} else {
df3 <- df2
}
# Devuelve el df con one-hot encoding
return (df3)
}
promoters <- read.csv('promoters.txt',header = FALSE,sep=',')
prueba <- onehot(df=promoters, col_seq = 'V3', onehot_cols_name = 'P-', remove_col_seq = TRUE)
prueba <- onehot(df=promoters, col_seq = 'V3', onehot_cols_name = 'miguel.', remove_col_seq = TRUE)
View(prueba)
promoters <- read.csv('promoters.txt',header = FALSE,sep=',')
prueba <- onehot(df=promoters, col_seq = 'V3', onehot_cols_name = 'P.', remove_col_seq = TRUE)
View(prueba)
##################################### LIBRERÍAS ########################################
library('class')
##################################### LIBRERÍAS ########################################
library('class','dplyr')
split_train_test <- function(df, size = 0.7) {
t <- floor(size * nrow(df))
train_ind <- sample(seq_len(nrow(df)), size = t)
train <- df[train_ind,]
test <- df[-train_ind,]
return (train, test)
}
train, test <- split_train_test(prueba)
split_train_test <- function(df, size = 0.7) {
t <- floor(size * nrow(df))
train_ind <- sample(seq_len(nrow(df)), size = t)
train <- df[train_ind,]
test <- df[-train_ind,]
return (list(train, test))
}
split_train_test <- function(df, size = 0.7) {
t <- floor(size * nrow(df))
train_ind <- sample(seq_len(nrow(df)), size = t)
train <- df[train_ind,]
test <- df[-train_ind,]
return (list(train, test))
}
c(train, test) %<-% split_train_test(prueba)
c(train, test) <- split_train_test(prueba)
split_train_test <- function(df, size = 0.7) {
t <- floor(size * nrow(df))
train_ind <- sample(seq_len(nrow(df)), size = t)
train <- df[train_ind,]
test <- df[-train_ind,]
return (list('train' = train, 'test' = test))
}
train <- split_train_test(prueba)$train
test <- split_train_test(prueba)$test
View(train)
View(test)
View(train)
split_train_test <- function(df, size = 0.7) {
''' Devuelve un "diccionario" con el DF
partido en train y test
'''
t <- floor(size * nrow(df))
train_ind <- sample(seq_len(nrow(df)), size = t)
train <- df[train_ind,]
test <- df[-train_ind,]
return (list('train' = train, 'test' = test))
}
install('randomForest')
install.packages('randomForest')
install.packages('c50')
install.packages('C50')
View(prueba)
View(promoters_onehot)
View(promoters_onehot)
prueba <- prueba[,-2]
View(prueba)
###################################### EJECUCIÓN ######################################
# PRE-PROCESAMIENTO DE DATOS
df1 <- promoters[,-2] # quitamos la columna "name"
df2 <- onehot(df=df1, col_seq = 'V3', onehot_cols_name = 'P.', remove_col_seq = TRUE)
View(df2)
table(df2$V1)
summary(df2$P.1)
set.seed(123)
train_labels <- train[,1]
train_labels
train_labels <- train[,1]
train_labels <- test[,1]
kneighbors <- knn(train,test,class=train_labels,k)
train_labels <- train[,1]
kneighbors <- knn(train,test,class=train_labels,k)
kneighbors <- knn(train=train,test=test,class=train_labels,k = 3)
kneighbors <- knn(train=train, test=test, cl = train_labels, k = 3)
kneighbors <- knn(train=train, test=test, cl = train_labels, k = 1)
kneighbors <- knn(train = df_train, test = df_test, cl = train_labels, k = 1)
df_train <- split_train_test(prueba)$train
kneighbors <- knn(train = df_train, test = df_test, cl = train_labels, k = 1)
df_test <- split_train_test(prueba)$test
kneighbors <- knn(train = df_train, test = df_test, cl = train_labels, k = 1)
train_labels <- df_train[,1]
train_labels <- df_train[,1]
test_labels <- df_test[,1]
kneighbors <- knn(train = df_train, test = df_test, cl = train_labels, k = 1)
train_labels <- factor(df_train[,1])
kneighbors <- knn(train = df_train, test = df_test, cl = train_labels, k = 1)
train_labels <- as.numeric(factor(df_train[,1]))
train_labels
df_train <- split_train_test(prueba)$train
df_test <- split_train_test(prueba)$test
train_labels <- as.numeric(factor(df_train[,1]))
test_labels <- as.numeric(factor(de_test[,1]))
test_labels <- as.numeric(factor(df_test[,1]))
kneighbors <- knn(train = df_train, test = df_test, cl = train_labels, k = 1)
class(train_labels)
kneighbors <- knn(train = df_train, test = df_test, cl = train_labels, k = 1)
train_labels <- as.integer(factor(df_train[,1]))
kneighbors <- knn(train = df_train, test = df_test, cl = train_labels, k = 1)
train_labels <- as.double(factor(df_train[,1]))
for (i in train_labels) {
print(as.double(i))
}
print(as.integer(i))
for (i in train_labels) {
print(as.integer(i))
}
df_train <- split_train_test(prueba)$train
df_test <- split_train_test(prueba)$test
View(df_train)
train_labels <- factor(df_train[,1])
train_labels
kneighbors <- knn(train = df_train, test = df_test, cl = train_labels, k = 1)
for (i in train_labels) {
as.numeric(i)
}
for (i in train_labels) {
as.numeric(i)
break
}
train_labels[0]
train_labels[1]
train_labels[2]
as.numeric(train_labels[2])
as.numeric(train_labels[1])
as.numeric(train_labels[2])
str(train_labels)
train_labels <- as.character(df_train[,1])
str(train_labels)
kneighbors <- knn(train = df_train, test = df_test, cl = train_labels, k = 1)
View(df2)
###################################### EJECUCIÓN ######################################
# PRE-PROCESAMIENTO DE DATOS
df1 <- promoters[,-2] # quitamos la columna "name"
df2 <- onehot(df=df1, col_seq = 'V3', onehot_cols_name = 'P.', remove_col_seq = TRUE)
df2$V1 <- factor(df2$V1, levels = c("+", "-"), labels = c("Positivo", "Negativo"))
df_train <- split_train_test(prueba)$train
df_test <- split_train_test(prueba)$test
train_labels <- df_train[,1]
str(train_labels)
kneighbors <- knn(train = df_train, test = df_test, cl = train_labels, k = 1)
str(df_train)
summary(df_train)
kneighbors <- knn(train = df_train[-1,], test = df_test[-1,], cl = train_labels, k = 1)
df2$V1 <- factor(df2$V1, levels = c("+", "-"), labels = c("Positivo", "Negativo"))
df_train <- split_train_test(prueba)$train
df_test <- split_train_test(prueba)$test
train_labels <- df_train[,1]
kneighbors <- knn(train = df_train[-1,], test = df_test[-1,], cl = train_labels, k = 1)
View(df_train)
kneighbors <- knn(train = df_train[,-1], test = df_test[,-1], cl = train_labels, k = 1)
###################################### EJECUCIÓN ######################################
# PRE-PROCESAMIENTO DE DATOS
df1 <- promoters[,-2] # quitamos la columna "name"
df2 <- onehot(df=df1, col_seq = 'V3', onehot_cols_name = 'P.', remove_col_seq = TRUE)
train <- split_train_test(prueba)$train
test <- split_train_test(prueba)$test
train_labels <- df_train[,1]
test_labels <- df_test[,1]
kneighbors <- knn(train = df_train[,-1], test = df_test[,-1], cl = train_labels, k = 1)
###################################### EJECUCIÓN ######################################
# PRE-PROCESAMIENTO DE DATOS
df1 <- promoters[,-2] # quitamos la columna "name"
df2 <- onehot(df=df1, col_seq = 'V3', onehot_cols_name = 'P.', remove_col_seq = TRUE)
train <- split_train_test(prueba)$train
test <- split_train_test(prueba)$test
train_labels <- df_train[,1]
test_labels <- df_test[,1]
kneighbors <- knn(train = df_train[,-1], test = df_test[,-1], cl = train_labels, k = 1)
# K-NEIGHBORS
kneighbors_1 <- knn(train = df_train[,-1], test = df_test[,-1], cl = train_labels, k = 1)
kneighbors_3 <- knn(train = df_train[,-1], test = df_test[,-1], cl = train_labels, k = 3)
kneighbors_5 <- knn(train = df_train[,-1], test = df_test[,-1], cl = train_labels, k = 5)
kneighbors_7 <- knn(train = df_train[,-1], test = df_test[,-1], cl = train_labels, k = 7)
CrossTable(x = test_labels, y = p, prop.chisq=FALSE)
install.packages('gmodels')
##################################### LIBRERÍAS ########################################
library('class','e1071','randomForest','kernlab','C50','neuralnet','gmodels')
library('gmodels')
##################################### LIBRERÍAS ########################################
library('class','e1071','randomForest','kernlab','C50','neuralnet','gmodels')
library('randomForest','kernlab','C50','neuralnet','gmodels')
##################################### LIBRERÍAS ########################################
library('class','e1071')
library('C50','neuralnet','gmodels')
##################################### LIBRERÍAS ########################################
library('class','e1071','randomForest')
##################################### LIBRERÍAS ########################################
library('class')
library('kernlab')
library('e1071')
library('randomForest')
library('C50')
library('neuralnet')
library('gmodels')
CrossTable(x = test_labels, y = p, prop.chisq=FALSE)
p <- predict(kneighbors_1, test, type = 'response')
CrossTable(x = test_labels, y = kneighbors_1, prop.chisq=FALSE)
###################################### EJECUCIÓN ######################################
# PRE-PROCESAMIENTO DE DATOS
df1 <- promoters[,-2] # quitamos la columna "name"
df2 <- onehot(df=df1, col_seq = 'V3', onehot_cols_name = 'P.', remove_col_seq = TRUE)
# SPLIT
train <- split_train_test(prueba)$train
test <- split_train_test(prueba)$test
train_labels <- df_train[,1]
test_labels <- df_test[,1]
# K-NEIGHBORS
kneighbors_1 <- knn(train = df_train[,-1], test = df_test[,-1], cl = train_labels, k = 1)
CrossTable(x = test_labels, y = kneighbors_1, prop.chisq=FALSE)
###################################### EJECUCIÓN ######################################
# PRE-PROCESAMIENTO DE DATOS
df1 <- promoters[,-2] # quitamos la columna "name"
df2 <- onehot(df=df1, col_seq = 'V3', onehot_cols_name = 'P.', remove_col_seq = TRUE)
df2$V1 <- factor(df2$V1, levels = c("+", "-"),        labels = c("Promotor", "No promotor"))
# SPLIT
train <- split_train_test(prueba)$train
test <- split_train_test(prueba)$test
round(prop.table(table(df2$V1)) * 100, digits = 1)
df2$V1 <- factor(df2$V1, levels = c("+", "-"), labels = c("Promotor", "No promotor"))
# SPLIT
train <- split_train_test(prueba)$train
test <- split_train_test(prueba)$test
train_labels <- df_train[,1]
test_labels <- df_test[,1]
# K-NEIGHBORS
kneighbors_1 <- knn(train = df_train[,-1], test = df_test[,-1], cl = train_labels, k = 1)
CrossTable(x = test_labels, y = kneighbors_1, prop.chisq=FALSE)
CrossTable(x = test_labels, y = kneighbors_1, prop.chisq=FALSE)$t
CrossTable(x = test_labels, y = kneighbors_1, prop.chisq=FALSE)$chisq
kneighbors_1_p <- CrossTable(x = test_labels, y = kneighbors_1, prop.chisq=FALSE)
kneighbors_3_p <- CrossTable(x = test_labels, y = kneighbors_3, prop.chisq=FALSE)
kneighbors_5_p <- CrossTable(x = test_labels, y = kneighbors_5, prop.chisq=FALSE)
kneighbors_7_p <- CrossTable(x = test_labels, y = kneighbors_7, prop.chisq=FALSE)
kneighbors <- function(train, test) {
train_labels <- train[,1]
test_labels <- test[,1]
kneighbors_1 <- knn(train = train[,-1], test = test[,-1], cl = train_labels, k = 1)
kneighbors_3 <- knn(train = train[,-1], test = test[,-1], cl = train_labels, k = 3)
kneighbors_5 <- knn(train = train[,-1], test = test[,-1], cl = train_labels, k = 5)
kneighbors_7 <- knn(train = train[,-1], test = test[,-1], cl = train_labels, k = 7)
kneighbors_1_p <- CrossTable(x = test_labels, y = kneighbors_1, prop.chisq=FALSE)
kneighbors_3_p <- CrossTable(x = test_labels, y = kneighbors_3, prop.chisq=FALSE)
kneighbors_5_p <- CrossTable(x = test_labels, y = kneighbors_5, prop.chisq=FALSE)
kneighbors_7_p <- CrossTable(x = test_labels, y = kneighbors_7, prop.chisq=FALSE)
return (list('k1'=kneighbors_1_p,'k3'=kneighbors_3_p,'k5'=kneighbors_5_p,'k7'=kneighbors_7_p))
}
NB <-
#########################################################################
naive_bayes <- naiveBayes(train, train_labels, laplace = 0)
naive_bayes_p <- predict(naive_bayes, test)
naive_bayes_cr <- CrossTable(x = naive_bayes_p, y = test_labels, prop.chisq = FALSE)
naive_bayes_p <- predict(naive_bayes, test)
naive_bayes_p
NB <-
#########################################################################
naive_bayes <- naiveBayes(train, train_labels, laplace =1)
naive_bayes_p <- predict(naive_bayes, test)
naive_bayes_p
NB <-
#########################################################################
naive_bayes <- naiveBayes(train, train_labels)
NB <-
#########################################################################
naive_bayes <- naiveBayes(train, train_labels)
naive_bayes_p <- predict(naive_bayes, test)
naive_bayes_cr <- CrossTable(x = naive_bayes_p, y = test_labels, prop.chisq = FALSE)
###################################### PRE-PROCESAMIENTO ##############################
df1 <- promoters[,-2] # quitamos la columna "name"
df2 <- onehot(df=df1, col_seq = 'V3', onehot_cols_name = 'P.', remove_col_seq = TRUE)
###################################### SPLIT ##########################################
train <- split_train_test(prueba)$train
test <- split_train_test(prueba)$test
train_labels <- df_train[,1]
test_labels <- df_test[,1]
NB <-
#########################################################################
naive_bayes <- naiveBayes(train, train_labels)
naive_bayes_p <- predict(naive_bayes, test)
naive_bayes_cr <- CrossTable(x = naive_bayes_p, y = test_labels, prop.chisq = FALSE)
naive_bayes_p
NB <-
#########################################################################
for (i in 1:ncol(df2)) {
df2[,i] <- as.character(df2[,i])
}
str(df2)
naive_bayes <- naiveBayes(train, train_labels)
naive_bayes_p <- predict(naive_bayes, test)
naive_bayes_cr <- CrossTable(x = naive_bayes_p, y = test_labels, prop.chisq = FALSE)
naive_bayes_p
install.packages('naivebayes')
naive_bayes <- naiveBayes(V1 ~ ., data = train[,-1])
naive_bayes <- naiveBayes(V1 ~ ., data = train)
naive_bayes_p <- predict(naive_bayes, test)
naive_bayes_p
naive_bayes <- naiveBayes(V1 ~ ., data = train)
naive_bayes_p <- predict(naive_bayes, test[,-1])
naive_bayes_p
naive_bayes
naive_bayes_p <- predict(naive_bayes, test)
naive_bayes_p
naive_bayes <- naiveBayes(V1 ~ ., data = train)
pred <- predict(naive_bayes, test)
tab <- table(test$V1, pred, dnn = c("Actual", "Predicha"))
###################################### SPLIT ##########################################
train <- split_train_test(prueba)$train
test <- split_train_test(prueba)$test
train_labels <- df_train[,1]
test_labels <- df_test[,1]
###################################### PRE-PROCESAMIENTO ##############################
df1 <- promoters[,-2] # quitamos la columna "name"
df2 <- onehot(df=df1, col_seq = 'V3', onehot_cols_name = 'P.', remove_col_seq = TRUE)
###################################### SPLIT ##########################################
train <- split_train_test(prueba)$train
test <- split_train_test(prueba)$test
train_labels <- df_train[,1]
test_labels <- df_test[,1]
str(test)
tab <- table(test$V1, pred, dnn = c("Actual", "Predicha"))
naive_bayes <- naiveBayes(V1 ~ ., data = train)
pred <- predict(naive_bayes, test)
pred
ann <- neuralnet(V1 ~ ., data = train, hidden = 1)
p <- compute(ann, test)
plot(ann)
p$net.result
ps <- p$net.result
p <- sapply(compute(ann, test), round, digits = 0)
p <- sapply(compute(ann, test)$net.result, round, digits = 0)
p
cor(p, test)
cor(p, test$P-1)
P
p
###################################### PRE-PROCESAMIENTO ##############################
df1 <- promoters[,-2] # quitamos la columna "name"
df2 <- onehot(df=df1, col_seq = 'V3', onehot_cols_name = 'P.', remove_col_seq = TRUE)
df2$V1 <- factor(df2$V1, levels = c("+", "-"), labels = c("Promotor", "No promotor"))
###################################### SPLIT ##########################################
train <- split_train_test(prueba)$train
test <- split_train_test(prueba)$test
train_labels <- df_train[,1]
test_labels <- df_test[,1]
##################################### RESULTADOS ####################################
KN <- kneighbors(train, test)$k1
NB <-
KN
NB <-
print(KN)
##################################### RESULTADOS ####################################
KN <- kneighbors(train, test)$k1
naive_bayes <- naiveBayes(V1 ~ ., data = train)
pred <- predict(naive_bayes, test)
naive_bayes_cr <- CrossTable(x = naive_bayes_p, y = test_labels, prop.chisq = FALSE)
head(pred)
###################################### PRE-PROCESAMIENTO ##############################
df1 <- promoters[,-2] # quitamos la columna "name"
df2 <- onehot(df=df1, col_seq = 'V3', onehot_cols_name = 'P.', remove_col_seq = TRUE)
df2$V1 <- factor(df2$V1, levels = c("+", "-"), labels = c("Promotor", "No promotor"))
###################################### SPLIT ##########################################
train <- split_train_test(prueba)$train
test <- split_train_test(prueba)$test
train_labels <- df_train[,1]
test_labels <- df_test[,1]
##################################### RESULTADOS ####################################
KN <- kneighbors(train, test)$k1
##################################### ALGORITMOS ######################################
ann <- neuralnet(formula = V1 ~ ., data = train, hidden = 1)
ann
