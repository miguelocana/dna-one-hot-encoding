---
title: Machine Learning - PEC3
author: "Miguel Ocaña Acosta"
date: "13/01/2020"
output:
  html_document:
    toc: TRUE
  pdf_document:
    toc: TRUE
---

<style>
  body {
  font-family: "Lato";
  text-align: justify;
  line-height : 25 px;
  }
</style>

---

# 1. Transformación de los datos

Primero, se importa el archivo y se guarda en una variable:
```{r}
promoters <- read.csv('promoters.txt',header = FALSE,sep=',')
promoters_onehot <- read.csv('promoters_onehot.txt', header = TRUE, sep=' ')
str(promoters)
summary(promoters)
```

Ahora transformamos las seqcuencias en one-hot encoding. Existe una opción muy conocida llamada *dummy*, que funciona de la siguiente manera:
```{r}
tutorial de dummy
```

Importamos el csv:
```{r}
promoters <- read.csv('promoters.txt',header = FALSE,sep=',')
promoters_onehot <- read.csv('promoters_onehot.txt', header = TRUE, sep=' ')
```

Ahora, cómo funciona el one-hot encoding:
```{r}
onehot <- function (df, col_seq, onehot_cols_name='H', remove_col_seq = FALSE) {
  # Se asegura de que todas las seq tengan el mismo tamaño (de lo contrario salta ERROR)
  f <- length(strsplit(df[col_seq][[1]], "")[[1]])
  for (j in 1:nrow(df)) {
    a = length(strsplit(df[j,col_seq], "")[[1]])
    if (a == f) {
      next
    } else {
      print('ERROR: al menos una secuencia no tiene el mismo tamaño que el resto.')
      break
    }
  }
  
  # Crea una columna por cada dígito del one-hot
  num_cols <- f * 4
  cols_onehot <- list()
  for (i in 1:num_cols) {
    cols_onehot <- append(cols_onehot,paste(onehot_cols_name,i,sep=""))
  }
  
  # Añade las columnas (vacías) al nuevo DF
  df2 <- df
  for (i in cols_onehot) {
    df2[,i] <- NA
  }
  
  # Traducción de seq a one-hot encoding
  for (j in 1:nrow(df2)) {
    seq = strsplit(tolower(df2[j,col_seq]), "")[[1]] # convierte la seq en minuscula
    seq_onehot <- list()
    for (i in seq) {
      if (i == 'a') {
        seq_onehot <- append(seq_onehot, c(0,0,0,1))
      } else if (i == 'g') {
        seq_onehot <- append(seq_onehot, c(0,0,1,0))
      } else if (i == 'c') {
        seq_onehot <- append(seq_onehot, c(0,1,0,0))
      } else if (i == 't') {
        seq_onehot <- append(seq_onehot, c(1,0,0,0))
      } else {
        print("ERROR: al menos un carácter de la secuencia introducida no corresponde a ningún nucleótido (A,G,C,T).")
        break
      }
    }
    for (k in 1:length(seq_onehot)) {
      ind <- grep(paste(onehot_cols_name,k,sep=""), colnames(df2))
      df2[j,ind] <- seq_onehot[k]
    }
  }
  
  # Elimina o no la columna con la secuencia
  if (remove_col_seq) {
    df3 <- df2[,c(x[-grep(col_seq, colnames(df2))])]
  } else {
    df3 <- df2
  }
}

```

La columna con el nombre de los promotores no da aporta ninguna información útil al modelo así que se elimina del df.
```{r}

```
\ 
# 2. Clasificación de los datos
## k-Nearest Neighbour
Se explorarán los valores para el número de vecinos k = 1,3,5,7
```{r}

```

## Naïve Bayes
Se explorará la opción de activar o no 'laplace'
```{r}

```

## Artificial Neural Network
Se explorarán el número de nodos de la capa oculta n - 4,5
```{r}

```

## Support Vector Machine
Se explorarán las funciones kernel lineal y rbf
```{r}

```

## Árbol de clasificación
Se explorará la opción de activar o no 'boosting',
```{r}

```

## Random Forest
Se explorarán la opción de número de árboles n - 50, 100
```{r}

```

# 3. Discusión final

# Anexo. Puntos Importantes.
#### 1. Implementar una función para realizar una transformación one-hot encoding de las secuencias del fichero de datos promoters.txt. En caso de no lograr la implementaación de dicha transformación, se puede utilizar el fichero promoters_onehot.txt con las secuencias codificados segun un one-hot para completar la actividad.
#### 2. En cada algoritmo hay que realizar las siguientes etapas: 1) Entrenar el modelo 2) Predicción y Evaluacióndel algoritmo. Será necesario "tunear" diferentes valores de los hiperparámetros del algoritmo paraposteriormente evaluar su rendimiento.
#### 3. Se debe aplicar la misma selección de datos training y test en todos los algoritmos. Utilizando la semilla aleatoria 123, para separar los datos en dos partes, una parte para training (67%) y otra partepara test (33%). Opcionalmente, se puede escoger otro tipo de partición del conjunto de training parahacer la validación como por ejemplo k-fold crossvalidation, boostrap, random splitting, etc. Lo que esimportante es mantener la misma selección para todos los algoritmos.
#### 4. En todos los casos se evalua la calidad del algoritmo con la información obtenida de la funciónconfusionMatrix() del paquete caret.
#### 5. Para la ejecución especifica de cada algoritmo se puede usar la función de cada algoritmo como sepresenta en el libro de referencia o usar el paquete caret con los diferentes modelos de los algoritmos. O incluso, hacer una versión mixta.



